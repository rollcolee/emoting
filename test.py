import cv2
import mediapipe as mp
import numpy as np
import pandas as pd
import xgboost as xgb
import json
from collections import Counter
from google.colab.patches import cv2_imshow  # Colabì—ì„œ ì´ë¯¸ì§€ ì¶œë ¥ìš©

# âœ… Google Driveì—ì„œ ëª¨ë¸ ë¡œë“œ
pose_model = xgb.XGBClassifier()
pose_model.load_model("/content/drive/MyDrive/2ì°¨í”„ë¡œì íŠ¸/ìì„¸ëª¨ë¸/pose_classification_model.json")

# âœ… JSON íŒŒì¼ ë¡œë“œ
with open("/content/drive/MyDrive/2ì°¨í”„ë¡œì íŠ¸/í‘œì •ëª¨ë¸/face_expression_model.json", "r", encoding="utf-8") as f:
    expression_model_data = json.load(f)

with open("/content/drive/MyDrive/2ì°¨í”„ë¡œì íŠ¸/ìì„¸ëª¨ë¸/label_encoder.json", "r", encoding="utf-8") as f:
    pose_label_map = json.load(f)

with open("/content/drive/MyDrive/2ì°¨í”„ë¡œì íŠ¸/í‘œì •ëª¨ë¸/face_label_encoder.json", "r", encoding="utf-8") as f:
    expression_label_map = json.load(f)

# âœ… MediaPipe ì´ˆê¸°í™”
mp_pose = mp.solutions.pose
mp_face_mesh = mp.solutions.face_mesh
pose = mp_pose.Pose()
face_mesh = mp_face_mesh.FaceMesh()

# âœ… ìì„¸ ë° í‘œì • ì¹´ìš´íŠ¸
pose_counter = Counter()
expression_counter = Counter()

def extract_pose_landmarks(frame):
    """ í”„ë ˆì„ì—ì„œ ìì„¸ì˜ ëœë“œë§ˆí¬ë¥¼ ì¶”ì¶œí•˜ì—¬ ëª¨ë¸ ì…ë ¥ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ """
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    result = pose.process(frame_rgb)

    if result.pose_landmarks:
        landmarks = np.array([[lm.x, lm.y, lm.z] for lm in result.pose_landmarks.landmark]).flatten()
        landmarks = landmarks[:93]  # ëª¨ë¸ ì…ë ¥ í¬ê¸° ë§ì¶¤
        return landmarks
    return None

def extract_face_landmarks(frame):
    """ í”„ë ˆì„ì—ì„œ ì–¼êµ´ì˜ ëœë“œë§ˆí¬ë¥¼ ì¶”ì¶œí•˜ì—¬ ëª¨ë¸ ì…ë ¥ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ """
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    result = face_mesh.process(frame_rgb)
    if result.multi_face_landmarks:
        face = result.multi_face_landmarks[0]
        return np.array([[lm.x, lm.y, lm.z] for lm in face.landmark][:25]).flatten()
    return None

def classify_pose(landmarks):
    """ ìì„¸ë¥¼ ë¶„ë¥˜í•˜ê³  ì¹´ìš´íŠ¸ """
    if landmarks is not None:
        pred = pose_model.predict([landmarks])[0]
        label = pose_label_map.get(str(pred), "Unknown")
        pose_counter[label] += 1
        return label
    return "Unknown"

def classify_expression(landmarks):
    """ í‘œì •ì„ ë¶„ë¥˜í•˜ê³  ì¹´ìš´íŠ¸ """
    if landmarks is not None:
        if "learner" in expression_model_data:
            pred = str(int(expression_model_data["learner"].get(str(landmarks.tolist()), -1)))
            label = expression_label_map.get(pred, "Unknown")
            expression_counter[label] += 1
            return label
        else:
            return "Unknown"
    return "Unknown"

def process_video(video_path, output_path):
    """ ë¹„ë””ì˜¤ì—ì„œ ìì„¸ ë° í‘œì •ì„ ë¶„ì„í•˜ê³  ê²°ê³¼ë¥¼ ì €ì¥ """
    cap = cv2.VideoCapture(video_path)

    if not cap.isOpened():
        print(f"âš ï¸ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
        return

    # âœ… ë™ì˜ìƒ ì €ì¥ ì„¤ì • (MP4)
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    frame_width, frame_height = int(cap.get(3)), int(cap.get(4))
    out = cv2.VideoWriter(output_path, fourcc, 20.0, (frame_width, frame_height))

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        # ğŸ”„ í”„ë ˆì„ 180ë„ íšŒì „ (Colabì—ì„œ ê±°ê¾¸ë¡œ ì¶œë ¥ ë°©ì§€)
        frame = cv2.flip(frame, 0)

        pose_landmarks = extract_pose_landmarks(frame)
        face_landmarks = extract_face_landmarks(frame)

        pose_label = classify_pose(pose_landmarks)
        expression_label = classify_expression(face_landmarks)

        # âœ… ë¹„ë””ì˜¤ì— í…ìŠ¤íŠ¸ ì¶”ê°€ (ìì„¸ & í‘œì •)
        cv2.putText(frame, f"Pose: {pose_label}", (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)
        cv2.putText(frame, f"Expression: {expression_label}", (30, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

        out.write(frame)  # âœ… ë™ì˜ìƒ ì €ì¥

    cap.release()
    out.release()

    # âœ… CSV ì €ì¥ (ë°ì´í„° ê¸¸ì´ ë§ì¶¤)
    max_length = max(len(pose_counter), len(expression_counter))
    pose_labels = list(pose_counter.keys()) + ["Unknown"] * (max_length - len(pose_counter))
    pose_counts = list(pose_counter.values()) + [0] * (max_length - len(pose_counter))
    expression_labels = list(expression_counter.keys()) + ["Unknown"] * (max_length - len(expression_counter))
    expression_counts = list(expression_counter.values()) + [0] * (max_length - len(expression_counter))

    result_df = pd.DataFrame({"Pose": pose_labels, "Pose Count": pose_counts,
                              "Expression": expression_labels, "Expression Count": expression_counts})
    result_df.to_csv("/content/pose_expression_count.csv", index=False)

    print("âœ… ê²°ê³¼ ë™ì˜ìƒê³¼ CSV ì €ì¥ ì™„ë£Œ!")

# âœ… ì‚¬ìš© ì˜ˆì‹œ (Google Driveì—ì„œ ë¹„ë””ì˜¤ ì½ê³  Colabì— ì €ì¥)
process_video("/content/drive/MyDrive/2ì°¨í”„ë¡œì íŠ¸/IMG_1493 (1).mov", "/content/processed_output.mp4")

# âœ… Colabì—ì„œ ë‹¤ìš´ë¡œë“œ (ì„ íƒ ì‚¬í•­)
from google.colab import files
files.download('/content/processed_output.mp4')  # ë™ì˜ìƒ ë‹¤ìš´ë¡œë“œ
files.download('/content/pose_expression_count.csv')  # CSV ë‹¤ìš´ë¡œë“œ
