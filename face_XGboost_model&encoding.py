í‘œì •ì— ëŒ€í•œ ì¢Œí‘œí•™ìŠµ ëª¨ë¸ ì €ì¥, ë¼ë²¨ ì¸ì½”ë”© ì •ë³´ ì €ì¥

import pandas as pd
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score
import json
import numpy as np

# 1. í•™ìŠµ ì¤€ë¹„ : ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df_face=pd.read_csv('/content/face_25_4000.csv')
df_face

# 'your_data.csv'ë¥¼ ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¡œ ë³€ê²½í•˜ì„¸ìš”.
train_df = df_face[df_face['dataset'] == 'train']
test_df = df_face[df_face['dataset'] == 'test']

# ë¼ë²¨ ë¶„ë¦¬
X_train = train_df.drop(columns=["image", "label","dataset"], axis=1)
y_train = train_df["label"]
X_test = test_df.drop(columns=["image", "label","dataset"], axis=1)
y_test = test_df["label"]

print(X_train, y_train)
print(X_test, y_test)

# ë¼ë²¨ ì¸ì½”ë”©
label_encoder = LabelEncoder()
y_train_encoded = label_encoder.fit_transform(y_train)
y_test_encoded = label_encoder.transform(y_test)

# âœ… ë³€í™˜ëœ y ê°’ í™•ì¸
print("ğŸ”¹ ë³€í™˜ëœ y_train:", np.unique(y_train_encoded))
print("ğŸ”¹ ë³€í™˜ëœ y_test:", np.unique(y_test_encoded))

# 2. XGBoost ëª¨ë¸ í•™ìŠµ
model = xgb.XGBClassifier(objective="multi:softmax", num_class=len(label_encoder.classes_), random_state=42)
model.fit(X_train, y_train_encoded)

# 3. ì˜ˆì¸¡ ë° í‰ê°€
y_pred_encoded = model.predict(X_test)
accuracy = accuracy_score(y_test_encoded, y_pred_encoded)
print(f"XG Test Accuracy: {accuracy:.4f}")

# 4. ëª¨ë¸ ì €ì¥
model.save_model("/content/face_expression_model.json")

# 5. ë¼ë²¨ ì¸ì½”ë”© ì •ë³´ ì €ì¥
with open("/content/face_label_encoder.json", "w") as f:
    json.dump({i: label for i, label in enumerate(label_encoder.classes_)}, f)
